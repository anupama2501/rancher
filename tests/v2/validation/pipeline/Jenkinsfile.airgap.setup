#!groovy
node {
  def homePath = pwd() + "/"
  def rootPath = "/root/go/src/github.com/rancher/tfp-automation/"
  def TERRAFORM_DIR = '/root/go/src/github.com/rancher/tfp-automation/modules/airgap'
  def testsDir = "github.com/rancher/tfp-automation/tests/${env.TEST_PACKAGE}"
  def job_name = "${JOB_NAME}"
  if (job_name.contains('/')) { 
    job_names = job_name.split('/')
    job_name = job_names[job_names.size() - 1] 
  }
  def testContainer = "${job_name}${env.BUILD_NUMBER}_test"
  def imageName = "tfp-automation-validation-${job_name}${env.BUILD_NUMBER}"
  def testResultsOut = "results.xml"
  def testResultsJSON = "results.json"
  def envFile = ".env"
  def config = env.CONFIG
  def testPackage = env.TEST_PACKAGE?.trim()
  def branch = "${env.BRANCH}"
  if ("${env.BRANCH}" != "null" && "${env.BRANCH}" != "") {
        branch = "${env.BRANCH}"
  }
  def repo = scm.userRemoteConfigs
  if ("${env.REPO}" != "null" && "${env.REPO}" != "") {
    repo = [[url: "${env.REPO}"]]
  }
  def timeout = "${env.TIMEOUT}"
  if ("${env.TIMEOUT}" != "null" && "${env.TIMEOUT}" != "") {
        timeout = "${env.TIMEOUT}" 
  }
  def s3Config = env.AWS_S3_BUCKET_CONFIG
  def AWS_S3_BUCKET = s3Config.s3Bucket
  def AWS_S3_REGION = s3Config.s3BucketRegion

  withCredentials([ string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
                    string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
                    string(credentialsId: 'RANCHER_LINODE_ACCESSKEY', variable: 'RANCHER_LINODE_ACCESSKEY'),
                    string(credentialsId: 'AWS_SSH_PEM_KEY', variable: 'AWS_SSH_PEM_KEY'),
                    string(credentialsId: 'AWS_SSH_KEY_NAME', variable: 'AWS_SSH_KEY_NAME'),
                    string(credentialsId: 'QASE_AUTOMATION_TOKEN', variable: 'QASE_AUTOMATION_TOKEN')]) {
      stage('Checkout') {
              deleteDir()
              checkout([
                        $class: 'GitSCM',
                        branches: [[name: "*/${branch}"]],
                        extensions: scm.extensions + [[$class: 'CleanCheckout']],
                        userRemoteConfigs: repo
                      ])
            }
        stage('Configure and Build') {
          config = config.replace('${AWS_SECRET_ACCESS_KEY}', env.AWS_SECRET_ACCESS_KEY)
          config = config.replace('${AWS_ACCESS_KEY_ID}', env.AWS_ACCESS_KEY_ID)

          writeFile file: 'config.yml', text: config

          def decoded = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
          writeFile file: 'key.pem', text: decoded
          
          env.CATTLE_TEST_CONFIG=rootPath+'config.yml'

          sh "./configure.sh"
          sh "./build.sh"
        }
        if  (!(env.HA_CLEANUP.toBoolean())) {
          stage('Run Module Test') {
            try {
              sh """
                docker run --name ${testContainer} -t -v ${homePath}key.pem:${rootPath}key.pem --env-file ${envFile} ${imageName} sh -c "
                /root/go/bin/gotestsum --format standard-verbose --packages=${testsDir} --junitfile ${testResultsOut} --jsonfile ${testResultsJSON} -- -timeout=${timeout} -v ${params.TEST_CASE};
                if [ -f ${rootPath}reporter ]; then ${rootPath}reporter; fi"
              """
            } catch(err) {
                echo 'Test run had failures. Collecting results...'
            }
          }
          stage('Upload tf files to S3 bucket'){
            try{
                sh "docker cp ${testContainer}:/root/ ./"
                sh "ls -lR"
                script {
                  sh """
                      if ls $TERRAFORM_DIR/. 1> /dev/null 2>&1; then
                          echo "Terraform files found, starting upload."
                      else
                          echo "No Terraform files found!"
                          exit 1
                      fi
                        docker run --rm \
                          -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
                          -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
                          -e AWS_DEFAULT_REGION=$AWS_S3_REGION \
                          -v $TERRAFORM_DIR/:/root/terraform/ \
                          amazon/aws-cli \
                          s3 cp /workspace s3://$AWS_S3_BUCKET/terraform/ --recursive --exclude "*" --include "*.tf"
                      """
                  }
              }catch(err){
                  echo "Unable to get the output: ${err}"
                }
           }
        }else{
          stage('Cleanup setup'){
              script {
                sh """
                    docker run --rm \
                    -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
                    -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
                    -e AWS_DEFAULT_REGION=$AWS_S3_REGION \
                    amazon/aws-cli \
                    s3 cp s3://$AWS_S3_BUCKET/terraform/ $rootPath --recursive
                  """ 
                sh """
                  docker run --rm \
                  -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
                  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
                  -e AWS_DEFAULT_REGION=$AWS_S3_REGION \
                  amazon/aws-cli \
                  s3 rm s3://$AWS_S3_BUCKET/terraform/ --recursive
                 """   
                sh """             
                  ls -lR $rootPath
                  terraform init
                  terraform destroy
                """

              }
           }
        }
    }
}